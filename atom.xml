<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>橙子🍊</title>
  
  
  <link href="https://beibidesr.github.io/atom.xml" rel="self"/>
  
  <link href="https://beibidesr.github.io/"/>
  <updated>2023-11-01T18:53:14.038Z</updated>
  <id>https://beibidesr.github.io/</id>
  
  <author>
    <name>橙子🍊</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>tagspace文本分类模型</title>
    <link href="https://beibidesr.github.io/posts/cafb114d.html"/>
    <id>https://beibidesr.github.io/posts/cafb114d.html</id>
    <published>2023-11-01T18:49:28.000Z</published>
    <updated>2023-11-01T18:53:14.038Z</updated>
    
    <content type="html"><![CDATA[<h1>tagspace文本分类模型</h1><p><strong><a href="https://aistudio.baidu.com/aistudio/projectdetail/3238891">AI Studio在线运行环境</a></strong></p><p>以下是本例的简要目录结构及说明：</p><figure class="highlight haxe"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">├── data <span class="meta">#样例数据</span></span><br><span class="line">    ├── train_data</span><br><span class="line">        ├── small_train.csv <span class="meta">#训练数据样例</span></span><br><span class="line">    ├── test_data</span><br><span class="line">        ├── small_test.csv <span class="meta">#测试数据样例</span></span><br><span class="line">    ├── text2paddle.py <span class="meta">#数据处理程序</span></span><br><span class="line">├── __init__.py</span><br><span class="line">├── README.md <span class="meta">#文档</span></span><br><span class="line">├── config.yaml <span class="meta"># sample数据配置</span></span><br><span class="line">├── config_bigdata.yaml <span class="meta"># 全量数据配置</span></span><br><span class="line">├── net.py <span class="meta"># 模型核心组网（动静统一）</span></span><br><span class="line">├── agnew<span class="type">s_reader</span>.py <span class="meta">#数据读取程序</span></span><br><span class="line">├── static_model.py <span class="meta"># 构建静态图</span></span><br><span class="line">├── dygraph_model.py <span class="meta"># 构建动态图</span></span><br></pre></td></tr></table></figure><p>注：在阅读该示例前，建议您先了解以下内容：</p><p><a href="https://github.com/PaddlePaddle/PaddleRec/blob/master/README.md">paddlerec入门教程</a><br><a href="https://paddlerec.readthedocs.io/en/latest/models/contentunderstanding/tagspace.html">tagespace</a></p><h2 id="内容">内容</h2><ul><li><a href="#tagspace%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B">tagspace文本分类模型</a><ul><li><a href="#%E5%86%85%E5%AE%B9">内容</a></li><li><a href="#%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B">模型简介</a></li><li><a href="#%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87">数据准备</a></li><li><a href="#%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83">运行环境</a></li><li><a href="#%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B">快速开始</a></li><li><a href="#%E6%A8%A1%E5%9E%8B%E7%BB%84%E7%BD%91">模型组网</a></li><li><a href="#%E6%95%88%E6%9E%9C%E5%A4%8D%E7%8E%B0">效果复现</a></li><li><a href="#%E8%BF%9B%E9%98%B6%E4%BD%BF%E7%94%A8">进阶使用</a></li><li><a href="#faq">FAQ</a></li></ul></li></ul><h2 id="模型简介">模型简介</h2><p>tagspace模型是一种对文本打标签的方法，来自论文论文<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.668.2094&amp;rep=rep1&amp;type=pdf">TAGSPACE: Semantic Embeddings from Hashtags</a>，它主要学习从短文到相关主题标签的映射。论文中主要利用CNN做doc向量， 然后优化 f(w,t+),f(w,t-)的距离作为目标函数，得到了 t（标签）和doc在一个特征空间的向量表达，这样就可以找 doc的hashtags了。</p><h2 id="数据准备">数据准备</h2><p>本模型使用论文中的ag_news数据集，在模型目录的data目录下为您准备了快速运行的示例数据，若需要使用全量数据可以参考下方<a href="#%E6%95%88%E6%9E%9C%E5%A4%8D%E7%8E%B0">效果复现</a>部分，数据的格式如下：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">2</span>,<span class="number">27</span> <span class="number">7062</span> <span class="number">8390</span> <span class="number">456</span> <span class="number">407</span> <span class="number">8</span> <span class="number">11589</span> <span class="number">3166</span> <span class="number">4</span> <span class="number">7278</span> <span class="number">31046</span> <span class="number">33</span> <span class="number">3898</span> <span class="number">2897</span> <span class="number">426</span> <span class="number">1</span></span><br><span class="line"><span class="attribute">2</span>,<span class="number">27</span> <span class="number">9493</span> <span class="number">836</span> <span class="number">355</span> <span class="number">20871</span> <span class="number">300</span> <span class="number">81</span> <span class="number">19</span> <span class="number">3</span> <span class="number">4125</span> <span class="number">9</span> <span class="number">449</span> <span class="number">462</span> <span class="number">13832</span> <span class="number">6</span> <span class="number">16570</span> <span class="number">1380</span> <span class="number">2874</span> <span class="number">5</span> <span class="number">0</span> <span class="number">797</span> <span class="number">236</span> <span class="number">19</span> <span class="number">3688</span> <span class="number">2106</span> <span class="number">14</span> <span class="number">8615</span> <span class="number">7</span> <span class="number">209</span> <span class="number">304</span> <span class="number">4</span> <span class="number">0</span> <span class="number">123</span> <span class="number">1</span></span><br><span class="line"><span class="attribute">2</span>,<span class="number">27</span> <span class="number">12754</span> <span class="number">637</span> <span class="number">106</span> <span class="number">3839</span> <span class="number">1532</span> <span class="number">66</span> <span class="number">0</span> <span class="number">379</span> <span class="number">6</span> <span class="number">0</span> <span class="number">1246</span> <span class="number">9</span> <span class="number">307</span> <span class="number">33</span> <span class="number">161</span> <span class="number">2</span> <span class="number">8100</span> <span class="number">36</span> <span class="number">0</span> <span class="number">350</span> <span class="number">123</span> <span class="number">101</span> <span class="number">74</span> <span class="number">181</span> <span class="number">0</span> <span class="number">6657</span> <span class="number">4</span> <span class="number">0</span> <span class="number">1222</span> <span class="number">17195</span> <span class="number">1</span></span><br></pre></td></tr></table></figure><p>可以看到，该数据集的格式为：<code>label,hashtag1,hashtag2,...,hashtagN</code>，其中label为文本的标签，hashtag为文本的hashtag。所以在最后进行推理过程中是使用计算相似度的方法得到损失函数。</p><h2 id="运行环境">运行环境</h2><p>PaddlePaddle&gt;=2.0</p><p>python 2.7/3.5/3.6/3.7</p><p>os : windows/linux/macos</p><h2 id="快速开始">快速开始</h2><p>本文提供了样例数据可以供您快速体验，在任意目录下均可执行。在tagspace模型目录的快速执行命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 进入模型目录</span></span><br><span class="line"><span class="comment"># cd models/contentunderstanding/tagspace # 在任意目录均可运行</span></span><br><span class="line"><span class="comment"># 动态图训练</span></span><br><span class="line">python -u ../../../tools/trainer.py -m config.yaml <span class="comment"># 全量数据运行config_bigdata.yaml </span></span><br><span class="line"><span class="comment"># 动态图预测</span></span><br><span class="line">python -u ../../../tools/infer.py -m config.yaml </span><br><span class="line"></span><br><span class="line"><span class="comment"># 静态图训练</span></span><br><span class="line">python -u ../../../tools/static_trainer.py -m config.yaml <span class="comment"># 全量数据运行config_bigdata.yaml </span></span><br><span class="line"><span class="comment"># 静态图预测</span></span><br><span class="line">python -u ../../../tools/static_infer.py -m config.yaml </span><br></pre></td></tr></table></figure><h2 id="模型组网">模型组网</h2><p>论文<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.668.2094&amp;rep=rep1&amp;type=pdf">TAGSPACE: Semantic Embeddings from Hashtags</a>中的网络结构如图所示，一层输入层，一个卷积层，一个pooling层以及最后一个全连接层进行降维。</p><p align="center"><img align="center" src="../../../doc/imgs/tagspace.png"><p>如上图所示，通过VScode对该代码进行debug后能够得到，该模型使用了卷积神经网络对于文本得到的embedding进行卷积处理，再进行pooling处理，最后进行全连接降维。loss function是通过计算cos函数得到相似度的差距来进行求导。## 效果复现为了方便使用者能够快速的跑通每一个模型，我们在每个模型下都提供了样例数据。如果需要复现readme中的效果,请按如下步骤依次操作即可。  在全量数据下模型的指标如下：<table><thead><tr><th style="text-align:left">模型</th><th style="text-align:left">acc</th><th style="text-align:left">batch_size</th><th style="text-align:left">epoch_num</th><th style="text-align:left">Time of each epoch</th></tr></thead><tbody><tr><td style="text-align:left">tagspace</td><td style="text-align:left">0.97</td><td style="text-align:left">128</td><td style="text-align:left">1</td><td style="text-align:left">约7分钟</td></tr></tbody></table><ol><li>确认您当前所在目录为PaddleRec/models/contentunderstanding/tagspace</li><li>进入paddlerec/datasets/ag_news目录下，执行该脚本，会从国内源的服务器上下载我们预处理完成的ag_news全量数据集，并解压到指定文件夹。</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ../../../datasets/ag_news</span><br><span class="line">sh run.sh</span><br></pre></td></tr></table></figure><ol start="3"><li>切回模型目录,执行命令运行全量数据</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> - <span class="comment"># 切回模型目录</span></span><br><span class="line"><span class="comment"># 动态图训练</span></span><br><span class="line">python -u ../../../tools/trainer.py -m config_bigdata.yaml <span class="comment"># 全量数据运行config_bigdata.yaml </span></span><br><span class="line">python -u ../../../tools/infer.py -m config_bigdata.yaml <span class="comment"># 全量数据运行config_bigdata.yaml </span></span><br></pre></td></tr></table></figure><h2 id="进阶使用">进阶使用</h2><h2 id="FAQ">FAQ</h2>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;tagspace文本分类模型&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://aistudio.baidu.com/aistudio/projectdetail/3238891&quot;&gt;AI Studio在线运行环境&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;以</summary>
      
    
    
    
    <category term="NLP" scheme="https://beibidesr.github.io/categories/NLP/"/>
    
    
    <category term="论文" scheme="https://beibidesr.github.io/tags/%E8%AE%BA%E6%96%87/"/>
    
    <category term="推荐" scheme="https://beibidesr.github.io/tags/%E6%8E%A8%E8%8D%90/"/>
    
    <category term="文本分类" scheme="https://beibidesr.github.io/tags/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"/>
    
  </entry>
  
  <entry>
    <title>单调队列在数据结构中的应用</title>
    <link href="https://beibidesr.github.io/posts/1dad47c4.html"/>
    <id>https://beibidesr.github.io/posts/1dad47c4.html</id>
    <published>2023-10-27T15:54:30.000Z</published>
    <updated>2023-10-27T16:12:10.219Z</updated>
    
    <content type="html"><![CDATA[<h1>1.Introduction</h1><p>单调队列是数据结构中的一种，其作用是维护一个队列，队列中的元素是单调递增或者单调递减的，并且队列中的元素都是按照顺序排列的。单调队列可以用于解决很多问题，例如求解滑动窗口的最大值和最小值，求解滑动窗口中所有元素的和，求解滑动窗口中所有元素的最大值等等。</p><h1>2.Leetcode题目</h1><h2 id="2-1-Sliding-Window-Maximum">2.1.Sliding Window Maximum</h2><h3 id="2-1-1-题目描述">2.1.1.题目描述</h3><p>给定一个数组 nums 和滑动窗口的大小 k，请找出所有滑动窗口里的最大值。</p><h3 id="2-1-2-示例">2.1.2.示例</h3><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入: nums = <span class="string">[1,3,-1,-3,5,3,6,7]</span>, 和 k = <span class="number">3</span></span><br><span class="line">输出: <span class="string">[3,3,5,5,6,7]</span>    </span><br></pre></td></tr></table></figure><h3 id="2-1-3-解题思路">2.1.3.解题思路</h3><p>滑动窗口的最大值问题，可以使用单调队列来解决。我们可以维护一个单调递减的队列，队列中的元素是单调递减的，并且队列中的元素都是按照顺序排列的。在滑动窗口中，我们每次将一个元素加入队列中，如果队列中已经存在了滑动窗口之外的元素，那么我们就将队列中已经存在的元素移除。当滑动窗口的大小为 k 时，我们就可以得到滑动窗口中的最大值。</p><h3 id="2-1-4-代码实现">2.1.4.代码实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">maxSlidingWindow</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], k: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        ans = []</span><br><span class="line">        q = deque()</span><br><span class="line">        <span class="keyword">for</span> i, x <span class="keyword">in</span> <span class="built_in">enumerate</span>(nums):</span><br><span class="line">            <span class="keyword">while</span> q <span class="keyword">and</span> nums[q[-<span class="number">1</span>]] &lt;= x:</span><br><span class="line">                q.pop()</span><br><span class="line">            q.append(i)</span><br><span class="line">            <span class="keyword">if</span> i - q[<span class="number">0</span>] &gt;= k:</span><br><span class="line">                q.popleft()</span><br><span class="line">            <span class="keyword">if</span> i &gt;= k - <span class="number">1</span>:</span><br><span class="line">                ans.append(nums[q[<span class="number">0</span>]])</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">单调队列在Leetcode中的应用学习</summary>
    
    
    
    <category term="Leetcode" scheme="https://beibidesr.github.io/categories/Leetcode/"/>
    
    
    <category term="数学" scheme="https://beibidesr.github.io/tags/%E6%95%B0%E5%AD%A6/"/>
    
    <category term="数据结构" scheme="https://beibidesr.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    <category term="单调队列" scheme="https://beibidesr.github.io/tags/%E5%8D%95%E8%B0%83%E9%98%9F%E5%88%97/"/>
    
    <category term="Leetcode" scheme="https://beibidesr.github.io/tags/Leetcode/"/>
    
  </entry>
  
  <entry>
    <title>随便写写</title>
    <link href="https://beibidesr.github.io/posts/380483a.html"/>
    <id>https://beibidesr.github.io/posts/380483a.html</id>
    <published>2023-10-19T10:11:05.000Z</published>
    <updated>2023-10-19T10:11:05.624Z</updated>
    
    
    
    
    
  </entry>
  
  <entry>
    <title>LLEMMA基于数学的问答语言模型学习记录</title>
    <link href="https://beibidesr.github.io/posts/bdb6f40d.html"/>
    <id>https://beibidesr.github.io/posts/bdb6f40d.html</id>
    <published>2023-10-19T09:19:03.000Z</published>
    <updated>2023-10-19T09:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1>1.Introduction</h1><div class="note info flat"><p>参考：<a href="https://blog.eleuther.ai/llemma/">Llemma：开放的数学语言模型</a></p></div><h2 id="1-1-LIemma模型介绍">1.1 LIemma模型介绍</h2><p>如图所示，Llemma 模型使用 Code Llama 权重进行初始化，然后在 Proof-Pile II（一个包含 550 亿个数学和科学文档的令牌数据集）上进行训练。由此产生的模型显示出改进的数学能力，并且可以通过提示或额外的微调来适应各种任务 `<img src="https://blog.eleuther.ai/images/blog/llemma/llemma_diagram.jpeg" alt="L1emma模型流程图"></p><h2 id="1-2-比较有意思的训练方法，也是语言模型微调常用方法">1.2 比较有意思的训练方法，也是语言模型微调常用方法</h2><p>这段代码是在训练一个基于LLM（语言模型）的文本生成模型。具体来说，它执行以下操作：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">1.</span> 解析命令行参数，包括模型、数据和训练参数。</span><br><span class="line"><span class="bullet">2.</span> 从预训练模型中加载模型架构。</span><br><span class="line"><span class="bullet">3.</span> 使用指定的分词器对输入数据进行编码。</span><br><span class="line"><span class="bullet">4.</span> 如果分词器没有填充标记，则添加默认的填充标记。</span><br><span class="line"><span class="bullet">5.</span> 如果模型名称包含&quot;llama&quot;，则为分词器添加特殊的结束符、开始符和未知标记。</span><br><span class="line"><span class="bullet">6.</span> 使用分词器和数据参数创建一个监督式数据模块。</span><br><span class="line"><span class="bullet">7.</span> 使用模型、分词器、训练参数和数据模块创建一个训练器对象。</span><br><span class="line"><span class="bullet">8.</span> 使用训练器对象进行训练。</span><br><span class="line"><span class="bullet">9.</span> 保存训练器的当前状态。</span><br><span class="line"><span class="bullet">10.</span> 将训练好的模型保存到指定的输出目录。</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>():</span><br><span class="line">    parser = transformers.HfArgumentParser((ModelArguments, DataArguments, TrainingArguments))</span><br><span class="line">    model_args, data_args, training_args, remaining_args = parser.parse_args_into_dataclasses(return_remaining_strings=<span class="literal">True</span>)</span><br><span class="line">    data_args.data_length = <span class="built_in">int</span>(remaining_args[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    model = transformers.AutoModelForCausalLM.from_pretrained(</span><br><span class="line">        model_args.model_name_or_path,</span><br><span class="line">        cache_dir=training_args.cache_dir,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    tokenizer = transformers.AutoTokenizer.from_pretrained(</span><br><span class="line">        <span class="string">&quot;hf-internal-testing/llama-tokenizer&quot;</span>,</span><br><span class="line">        cache_dir=training_args.cache_dir,</span><br><span class="line">        model_max_length=training_args.model_max_length,</span><br><span class="line">        padding_side=<span class="string">&quot;right&quot;</span>,</span><br><span class="line">        use_fast=<span class="literal">False</span>,</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">if</span> tokenizer.pad_token <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        smart_tokenizer_and_embedding_resize(</span><br><span class="line">            special_tokens_dict=<span class="built_in">dict</span>(pad_token=DEFAULT_PAD_TOKEN),</span><br><span class="line">            tokenizer=tokenizer,</span><br><span class="line">            model=model,</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&quot;llama&quot;</span> <span class="keyword">in</span> model_args.model_name_or_path:</span><br><span class="line">        tokenizer.add_special_tokens(</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="string">&quot;eos_token&quot;</span>: DEFAULT_EOS_TOKEN,</span><br><span class="line">                <span class="string">&quot;bos_token&quot;</span>: DEFAULT_BOS_TOKEN,</span><br><span class="line">                <span class="string">&quot;unk_token&quot;</span>: DEFAULT_UNK_TOKEN,</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    data_module = make_supervised_data_module(tokenizer=tokenizer, data_args=data_args)</span><br><span class="line">    trainer = Trainer(model=model, tokenizer=tokenizer, args=training_args, **data_module)</span><br><span class="line">    trainer.train()</span><br><span class="line">    trainer.save_state()</span><br><span class="line">    <span class="comment"># if os.environ.get(&#x27;LOCAL_RANK&#x27;) == &#x27;0&#x27;:</span></span><br><span class="line">    safe_save_model_for_hf_trainer(trainer=trainer, output_dir=training_args.output_dir)</span><br></pre></td></tr></table></figure><h2 id="1-3-论文贪心搜索的源码的阅读以及理解">1.3 论文贪心搜索的源码的阅读以及理解</h2><p>文章使用了贪心搜索的策略对于数据进行一定处理，代码如下:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">best_first_search</span>(<span class="params"></span></span><br><span class="line"><span class="params">        theorem,</span></span><br><span class="line"><span class="params">        model,</span></span><br><span class="line"><span class="params">        tokenizer,</span></span><br><span class="line"><span class="params">        max_iters,</span></span><br><span class="line"><span class="params">        temperatures,</span></span><br><span class="line"><span class="params">        num_samples,</span></span><br><span class="line"><span class="params">        prompt_fn,</span></span><br><span class="line"><span class="params">        timeout=<span class="number">600</span>,</span></span><br><span class="line"><span class="params">        early_stop=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">        max_tokens=<span class="number">256</span></span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="built_in">dict</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Best first search.&quot;&quot;&quot;</span></span><br><span class="line">    attempt_results = []</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">with</span> Dojo(theorem, hard_timeout=timeout) <span class="keyword">as</span> (dojo, init_state):</span><br><span class="line">            start = time.time()</span><br><span class="line">            proof_finished = <span class="literal">False</span></span><br><span class="line">            queue = [(<span class="number">0.0</span>, [], init_state, [])]</span><br><span class="line">            visited = <span class="built_in">set</span>()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> iteration <span class="keyword">in</span> trange(max_iters):</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(queue) == <span class="number">0</span> <span class="keyword">or</span> proof_finished:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">                total_score, steps, state, trace = heapq.heappop(queue)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这段代码是一个名为<code>best_first_search</code>的函数，它实现了一种称为&quot;最佳优先搜索&quot;（Best First Search）的算法。这个算法用于在给定的定理和模型中寻找证明的最佳路径。<br>函数接受以下参数：</p><ul><li><code>theorem</code>：需要证明的定理对象。</li><li><code>model</code>：用于生成证明的语言模型。</li><li><code>tokenizer</code>：用于将文本转换为模型可以理解的输入格式的分词器。</li><li><code>max_iters</code>：最大迭代次数，即搜索的最大深度。</li><li><code>temperatures</code>：一个温度值列表，用于控制语言模型生成的概率分布。</li><li><code>num_samples</code>：每个步骤中从语言模型中采样的次数。</li><li><code>prompt_fn</code>：一个函数，根据当前的状态生成提示信息。</li><li><code>timeout</code>：搜索超时时间，单位为秒。</li><li><code>early_stop</code>：是否在找到第一个有效证明后提前停止搜索。</li><li><code>max_tokens</code>：生成的提示信息的最大长度。</li></ul><p>函数返回一个字典列表，每个字典包含以下键值对：</p><ul><li><code>'theorem'</code>：定理的全名。</li><li><code>'proof'</code>：证明的步骤序列。</li><li><code>'score'</code>：证明的得分，表示该证明的质量。</li><li><code>'success'</code>：证明是否成功。</li><li><code>'failure_reason'</code>：证明失败的原因。</li><li><code>'trace'</code>：证明过程中的轨迹信息。</li><li><code>'temperature'</code>：使用的模型温度。</li><li><code>'elapsed'</code>：搜索所花费的时间。</li><li><code>'iteration'</code>：当前的迭代次数。</li></ul>]]></content>
    
    
    <summary type="html">🥧LLEMMA基于数学的问答语言模型学习记录</summary>
    
    
    
    <category term="NLP" scheme="https://beibidesr.github.io/categories/NLP/"/>
    
    
    <category term="Markdown" scheme="https://beibidesr.github.io/tags/Markdown/"/>
    
    <category term="语言模型" scheme="https://beibidesr.github.io/tags/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/"/>
    
    <category term="L1mma" scheme="https://beibidesr.github.io/tags/L1mma/"/>
    
    <category term="数学" scheme="https://beibidesr.github.io/tags/%E6%95%B0%E5%AD%A6/"/>
    
  </entry>
  
</feed>
