<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>æ©™å­ğŸŠ</title>
  
  
  <link href="https://beibidesr.github.io/atom.xml" rel="self"/>
  
  <link href="https://beibidesr.github.io/"/>
  <updated>2023-10-19T10:11:05.624Z</updated>
  <id>https://beibidesr.github.io/</id>
  
  <author>
    <name>æ©™å­ğŸŠ</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>éšä¾¿å†™å†™</title>
    <link href="https://beibidesr.github.io/posts/380483a.html"/>
    <id>https://beibidesr.github.io/posts/380483a.html</id>
    <published>2023-10-19T10:11:05.000Z</published>
    <updated>2023-10-19T10:11:05.624Z</updated>
    
    
    
    
    
  </entry>
  
  <entry>
    <title>LLEMMAåŸºäºæ•°å­¦çš„é—®ç­”è¯­è¨€æ¨¡å‹å­¦ä¹ è®°å½•</title>
    <link href="https://beibidesr.github.io/posts/bdb6f40d.html"/>
    <id>https://beibidesr.github.io/posts/bdb6f40d.html</id>
    <published>2023-10-19T09:19:03.000Z</published>
    <updated>2023-10-19T09:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1>1.Introduction</h1><div class="note info flat"><p>å‚è€ƒï¼š<a href="https://blog.eleuther.ai/llemma/">Llemmaï¼šå¼€æ”¾çš„æ•°å­¦è¯­è¨€æ¨¡å‹</a></p></div><h2 id="1-1-LIemmaæ¨¡å‹ä»‹ç»">1.1 LIemmaæ¨¡å‹ä»‹ç»</h2><p>å¦‚å›¾æ‰€ç¤ºï¼ŒLlemma æ¨¡å‹ä½¿ç”¨ Code Llama æƒé‡è¿›è¡Œåˆå§‹åŒ–ï¼Œç„¶ååœ¨ Proof-Pile IIï¼ˆä¸€ä¸ªåŒ…å« 550 äº¿ä¸ªæ•°å­¦å’Œç§‘å­¦æ–‡æ¡£çš„ä»¤ç‰Œæ•°æ®é›†ï¼‰ä¸Šè¿›è¡Œè®­ç»ƒã€‚ç”±æ­¤äº§ç”Ÿçš„æ¨¡å‹æ˜¾ç¤ºå‡ºæ”¹è¿›çš„æ•°å­¦èƒ½åŠ›ï¼Œå¹¶ä¸”å¯ä»¥é€šè¿‡æç¤ºæˆ–é¢å¤–çš„å¾®è°ƒæ¥é€‚åº”å„ç§ä»»åŠ¡ `<img src="https://blog.eleuther.ai/images/blog/llemma/llemma_diagram.jpeg" alt="L1emmaæ¨¡å‹æµç¨‹å›¾"></p><h2 id="1-2-æ¯”è¾ƒæœ‰æ„æ€çš„è®­ç»ƒæ–¹æ³•ï¼Œä¹Ÿæ˜¯è¯­è¨€æ¨¡å‹å¾®è°ƒå¸¸ç”¨æ–¹æ³•">1.2 æ¯”è¾ƒæœ‰æ„æ€çš„è®­ç»ƒæ–¹æ³•ï¼Œä¹Ÿæ˜¯è¯­è¨€æ¨¡å‹å¾®è°ƒå¸¸ç”¨æ–¹æ³•</h2><p>è¿™æ®µä»£ç æ˜¯åœ¨è®­ç»ƒä¸€ä¸ªåŸºäºLLMï¼ˆè¯­è¨€æ¨¡å‹ï¼‰çš„æ–‡æœ¬ç”Ÿæˆæ¨¡å‹ã€‚å…·ä½“æ¥è¯´ï¼Œå®ƒæ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">1.</span> è§£æå‘½ä»¤è¡Œå‚æ•°ï¼ŒåŒ…æ‹¬æ¨¡å‹ã€æ•°æ®å’Œè®­ç»ƒå‚æ•°ã€‚</span><br><span class="line"><span class="bullet">2.</span> ä»é¢„è®­ç»ƒæ¨¡å‹ä¸­åŠ è½½æ¨¡å‹æ¶æ„ã€‚</span><br><span class="line"><span class="bullet">3.</span> ä½¿ç”¨æŒ‡å®šçš„åˆ†è¯å™¨å¯¹è¾“å…¥æ•°æ®è¿›è¡Œç¼–ç ã€‚</span><br><span class="line"><span class="bullet">4.</span> å¦‚æœåˆ†è¯å™¨æ²¡æœ‰å¡«å……æ ‡è®°ï¼Œåˆ™æ·»åŠ é»˜è®¤çš„å¡«å……æ ‡è®°ã€‚</span><br><span class="line"><span class="bullet">5.</span> å¦‚æœæ¨¡å‹åç§°åŒ…å«&quot;llama&quot;ï¼Œåˆ™ä¸ºåˆ†è¯å™¨æ·»åŠ ç‰¹æ®Šçš„ç»“æŸç¬¦ã€å¼€å§‹ç¬¦å’ŒæœªçŸ¥æ ‡è®°ã€‚</span><br><span class="line"><span class="bullet">6.</span> ä½¿ç”¨åˆ†è¯å™¨å’Œæ•°æ®å‚æ•°åˆ›å»ºä¸€ä¸ªç›‘ç£å¼æ•°æ®æ¨¡å—ã€‚</span><br><span class="line"><span class="bullet">7.</span> ä½¿ç”¨æ¨¡å‹ã€åˆ†è¯å™¨ã€è®­ç»ƒå‚æ•°å’Œæ•°æ®æ¨¡å—åˆ›å»ºä¸€ä¸ªè®­ç»ƒå™¨å¯¹è±¡ã€‚</span><br><span class="line"><span class="bullet">8.</span> ä½¿ç”¨è®­ç»ƒå™¨å¯¹è±¡è¿›è¡Œè®­ç»ƒã€‚</span><br><span class="line"><span class="bullet">9.</span> ä¿å­˜è®­ç»ƒå™¨çš„å½“å‰çŠ¶æ€ã€‚</span><br><span class="line"><span class="bullet">10.</span> å°†è®­ç»ƒå¥½çš„æ¨¡å‹ä¿å­˜åˆ°æŒ‡å®šçš„è¾“å‡ºç›®å½•ã€‚</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>():</span><br><span class="line">    parser = transformers.HfArgumentParser((ModelArguments, DataArguments, TrainingArguments))</span><br><span class="line">    model_args, data_args, training_args, remaining_args = parser.parse_args_into_dataclasses(return_remaining_strings=<span class="literal">True</span>)</span><br><span class="line">    data_args.data_length = <span class="built_in">int</span>(remaining_args[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    model = transformers.AutoModelForCausalLM.from_pretrained(</span><br><span class="line">        model_args.model_name_or_path,</span><br><span class="line">        cache_dir=training_args.cache_dir,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    tokenizer = transformers.AutoTokenizer.from_pretrained(</span><br><span class="line">        <span class="string">&quot;hf-internal-testing/llama-tokenizer&quot;</span>,</span><br><span class="line">        cache_dir=training_args.cache_dir,</span><br><span class="line">        model_max_length=training_args.model_max_length,</span><br><span class="line">        padding_side=<span class="string">&quot;right&quot;</span>,</span><br><span class="line">        use_fast=<span class="literal">False</span>,</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">if</span> tokenizer.pad_token <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        smart_tokenizer_and_embedding_resize(</span><br><span class="line">            special_tokens_dict=<span class="built_in">dict</span>(pad_token=DEFAULT_PAD_TOKEN),</span><br><span class="line">            tokenizer=tokenizer,</span><br><span class="line">            model=model,</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&quot;llama&quot;</span> <span class="keyword">in</span> model_args.model_name_or_path:</span><br><span class="line">        tokenizer.add_special_tokens(</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="string">&quot;eos_token&quot;</span>: DEFAULT_EOS_TOKEN,</span><br><span class="line">                <span class="string">&quot;bos_token&quot;</span>: DEFAULT_BOS_TOKEN,</span><br><span class="line">                <span class="string">&quot;unk_token&quot;</span>: DEFAULT_UNK_TOKEN,</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    data_module = make_supervised_data_module(tokenizer=tokenizer, data_args=data_args)</span><br><span class="line">    trainer = Trainer(model=model, tokenizer=tokenizer, args=training_args, **data_module)</span><br><span class="line">    trainer.train()</span><br><span class="line">    trainer.save_state()</span><br><span class="line">    <span class="comment"># if os.environ.get(&#x27;LOCAL_RANK&#x27;) == &#x27;0&#x27;:</span></span><br><span class="line">    safe_save_model_for_hf_trainer(trainer=trainer, output_dir=training_args.output_dir)</span><br></pre></td></tr></table></figure><h2 id="1-3-è®ºæ–‡è´ªå¿ƒæœç´¢çš„æºç çš„é˜…è¯»ä»¥åŠç†è§£">1.3 è®ºæ–‡è´ªå¿ƒæœç´¢çš„æºç çš„é˜…è¯»ä»¥åŠç†è§£</h2><p>æ–‡ç« ä½¿ç”¨äº†è´ªå¿ƒæœç´¢çš„ç­–ç•¥å¯¹äºæ•°æ®è¿›è¡Œä¸€å®šå¤„ç†ï¼Œä»£ç å¦‚ä¸‹:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">best_first_search</span>(<span class="params"></span></span><br><span class="line"><span class="params">        theorem,</span></span><br><span class="line"><span class="params">        model,</span></span><br><span class="line"><span class="params">        tokenizer,</span></span><br><span class="line"><span class="params">        max_iters,</span></span><br><span class="line"><span class="params">        temperatures,</span></span><br><span class="line"><span class="params">        num_samples,</span></span><br><span class="line"><span class="params">        prompt_fn,</span></span><br><span class="line"><span class="params">        timeout=<span class="number">600</span>,</span></span><br><span class="line"><span class="params">        early_stop=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">        max_tokens=<span class="number">256</span></span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="built_in">dict</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Best first search.&quot;&quot;&quot;</span></span><br><span class="line">    attempt_results = []</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">with</span> Dojo(theorem, hard_timeout=timeout) <span class="keyword">as</span> (dojo, init_state):</span><br><span class="line">            start = time.time()</span><br><span class="line">            proof_finished = <span class="literal">False</span></span><br><span class="line">            queue = [(<span class="number">0.0</span>, [], init_state, [])]</span><br><span class="line">            visited = <span class="built_in">set</span>()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> iteration <span class="keyword">in</span> trange(max_iters):</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(queue) == <span class="number">0</span> <span class="keyword">or</span> proof_finished:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">                total_score, steps, state, trace = heapq.heappop(queue)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>è¿™æ®µä»£ç æ˜¯ä¸€ä¸ªåä¸º<code>best_first_search</code>çš„å‡½æ•°ï¼Œå®ƒå®ç°äº†ä¸€ç§ç§°ä¸º&quot;æœ€ä½³ä¼˜å…ˆæœç´¢&quot;ï¼ˆBest First Searchï¼‰çš„ç®—æ³•ã€‚è¿™ä¸ªç®—æ³•ç”¨äºåœ¨ç»™å®šçš„å®šç†å’Œæ¨¡å‹ä¸­å¯»æ‰¾è¯æ˜çš„æœ€ä½³è·¯å¾„ã€‚<br>å‡½æ•°æ¥å—ä»¥ä¸‹å‚æ•°ï¼š</p><ul><li><code>theorem</code>ï¼šéœ€è¦è¯æ˜çš„å®šç†å¯¹è±¡ã€‚</li><li><code>model</code>ï¼šç”¨äºç”Ÿæˆè¯æ˜çš„è¯­è¨€æ¨¡å‹ã€‚</li><li><code>tokenizer</code>ï¼šç”¨äºå°†æ–‡æœ¬è½¬æ¢ä¸ºæ¨¡å‹å¯ä»¥ç†è§£çš„è¾“å…¥æ ¼å¼çš„åˆ†è¯å™¨ã€‚</li><li><code>max_iters</code>ï¼šæœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œå³æœç´¢çš„æœ€å¤§æ·±åº¦ã€‚</li><li><code>temperatures</code>ï¼šä¸€ä¸ªæ¸©åº¦å€¼åˆ—è¡¨ï¼Œç”¨äºæ§åˆ¶è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„æ¦‚ç‡åˆ†å¸ƒã€‚</li><li><code>num_samples</code>ï¼šæ¯ä¸ªæ­¥éª¤ä¸­ä»è¯­è¨€æ¨¡å‹ä¸­é‡‡æ ·çš„æ¬¡æ•°ã€‚</li><li><code>prompt_fn</code>ï¼šä¸€ä¸ªå‡½æ•°ï¼Œæ ¹æ®å½“å‰çš„çŠ¶æ€ç”Ÿæˆæç¤ºä¿¡æ¯ã€‚</li><li><code>timeout</code>ï¼šæœç´¢è¶…æ—¶æ—¶é—´ï¼Œå•ä½ä¸ºç§’ã€‚</li><li><code>early_stop</code>ï¼šæ˜¯å¦åœ¨æ‰¾åˆ°ç¬¬ä¸€ä¸ªæœ‰æ•ˆè¯æ˜åæå‰åœæ­¢æœç´¢ã€‚</li><li><code>max_tokens</code>ï¼šç”Ÿæˆçš„æç¤ºä¿¡æ¯çš„æœ€å¤§é•¿åº¦ã€‚</li></ul><p>å‡½æ•°è¿”å›ä¸€ä¸ªå­—å…¸åˆ—è¡¨ï¼Œæ¯ä¸ªå­—å…¸åŒ…å«ä»¥ä¸‹é”®å€¼å¯¹ï¼š</p><ul><li><code>'theorem'</code>ï¼šå®šç†çš„å…¨åã€‚</li><li><code>'proof'</code>ï¼šè¯æ˜çš„æ­¥éª¤åºåˆ—ã€‚</li><li><code>'score'</code>ï¼šè¯æ˜çš„å¾—åˆ†ï¼Œè¡¨ç¤ºè¯¥è¯æ˜çš„è´¨é‡ã€‚</li><li><code>'success'</code>ï¼šè¯æ˜æ˜¯å¦æˆåŠŸã€‚</li><li><code>'failure_reason'</code>ï¼šè¯æ˜å¤±è´¥çš„åŸå› ã€‚</li><li><code>'trace'</code>ï¼šè¯æ˜è¿‡ç¨‹ä¸­çš„è½¨è¿¹ä¿¡æ¯ã€‚</li><li><code>'temperature'</code>ï¼šä½¿ç”¨çš„æ¨¡å‹æ¸©åº¦ã€‚</li><li><code>'elapsed'</code>ï¼šæœç´¢æ‰€èŠ±è´¹çš„æ—¶é—´ã€‚</li><li><code>'iteration'</code>ï¼šå½“å‰çš„è¿­ä»£æ¬¡æ•°ã€‚</li></ul>]]></content>
    
    
    <summary type="html">ğŸ¥§LLEMMAåŸºäºæ•°å­¦çš„é—®ç­”è¯­è¨€æ¨¡å‹å­¦ä¹ è®°å½•</summary>
    
    
    
    <category term="NLP" scheme="https://beibidesr.github.io/categories/NLP/"/>
    
    
    <category term="Markdown" scheme="https://beibidesr.github.io/tags/Markdown/"/>
    
    <category term="è¯­è¨€æ¨¡å‹" scheme="https://beibidesr.github.io/tags/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/"/>
    
    <category term="L1mma" scheme="https://beibidesr.github.io/tags/L1mma/"/>
    
    <category term="æ•°å­¦" scheme="https://beibidesr.github.io/tags/%E6%95%B0%E5%AD%A6/"/>
    
  </entry>
  
</feed>
